{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальное соревнование\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании вас ждет неизвестная зависимость. Ваша основная задача: **построить две лучших модели**, минимизирующих среднеквадратичную ошибку (MSE):\n",
    "1. На первую модель не налагается ограничений.\n",
    "2. Вторая модель должна быть **линейной**, т.е. представлять собой линейную комбинацию признаков плюс свободный член: $\\boldsymbol{w}^{\\top}\\boldsymbol{x} + b$. При этом __вы можете использовать базовые математические операции для преобразования признаков__: np.exp, np.log, np.pow (полный список доступен в [документации](https://numpy.org/doc/stable/reference/routines.math.html)), а также линейные операции над ними (сумма, умножение на число и пр.). Для преобразования признаков вам будет необходимо написать функцию `my_transformation`. __Кол-во параметров (весов) используемых второй моделью не должно превышать 15 (включая свободный член).__\n",
    "\n",
    "Настоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на готовые примеры, а не просто \"скопировать-вставить\". Это поможет вам в будущем писать код более уверенно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных происходит ниже. Если она не срабатывает, самостоятельно скачайте файл `hw_final_open_data.npy` и положите его в ту же директорию, что и ноутбук."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/23f_yandex_ml_trainings/homeworks/assignment_final/hw_final_open_data.npy -O hw_final_open_data.npy\n",
    "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/23f_yandex_ml_trainings/homeworks/assignment_final/hw_final_open_target.npy -O hw_final_open_target.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('hw_final_open_data.npy'), 'Please, download `hw_final_open_data.npy` and place it in the working directory'\n",
    "assert os.path.exists('hw_final_open_target.npy'), 'Please, download `hw_final_open_target.npy` and place it in the working directory'\n",
    "data = np.load('hw_final_open_data.npy', allow_pickle=False)\n",
    "target = np.load('hw_final_open_target.npy', allow_pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбивка на `closed_data` и `val` опциональна и сделана для вашего удобства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_data_x, valid_x, closed_data_y, valid_y = train_test_split(data, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель №1\n",
    "Напоминаем, в первой части задания ваша основная задача – получить наилучший результат без ограничений на модель. Сдаваться будут только предсказания модели.\n",
    "\n",
    "Пример с использованием Random Forest доступен ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(closed_data_x, closed_data_y)\n",
    "\n",
    "print(\n",
    "    f'closed_data mse =\\t {mean_squared_error(np.round(rf.predict(closed_data_x), 2), np.round(closed_data_y)):.5f}',\n",
    "    f'validation mse = {mean_squared_error(np.round(rf.predict(valid_x)), np.round(valid_y)):.5f}',\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сдача первой части соревнования\n",
    "Загрузите файл `hw_final_closed_data.npy` (ссылка есть на странице с заданием). Если вы используете sklearn-совместимую модель, для генерации посылки вы можете воспользоваться функцией `get_predictions`. В ином случае перепишите функцию для вашей модели и запустите код под следующей ячейкой для генерации посылки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/23f_yandex_ml_trainings/homeworks/assignment_final/hw_final_closed_data.npy -O hw_final_closed_data.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('hw_final_closed_data.npy'), 'Please, download `hw_final_closed_data.npy` and place it in the working directory'\n",
    "closed_data = np.load('hw_final_closed_data.npy', allow_pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если необходимо, преобразуйте данные. Преобразованную матрицу объект-признак сохраните в переменную `closed_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df.rename(columns={0: '0', 1: '1', 2: '2' , 3: '3', 4: '4', 5: '5', 6: '6'}, inplace=True)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_data = pd.DataFrame(closed_data)\n",
    "closed_data.rename(columns={0: '0', 1: '1', 2: '2' , 3: '3', 4: '4', 5: '5', 6: '6'}, inplace=True)\n",
    "closed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(df: pd.core.frame.DataFrame, column: str) -> tuple:\n",
    "    q_one = df[column].quantile(q=.25)\n",
    "    q_three  = df[column].quantile(q=.75)\n",
    "    iqr = q_three - q_one\n",
    "    left_border = q_one-(1.5*iqr)\n",
    "    right_border = q_three+(1.5*iqr)\n",
    "    outliers_left = df[df[column] < left_border]\n",
    "    outliers_right = df[df[column] > right_border]\n",
    "    full_outliers = len(outliers_left) + len(outliers_right)\n",
    "    return(full_outliers, left_border, right_border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_charts(df_columns: list) -> None:\n",
    "    num_chrt = len(df_columns)\n",
    "    for column in df_columns:\n",
    "\n",
    "        outliers_full, left_border_full, right_border_full = get_outliers(data_df, column)\n",
    "        fig = plt.figure(figsize=[20, 15])\n",
    "        grd = plt.GridSpec(ncols=1,nrows=2, top=0.92, wspace=0.15, hspace=0)\n",
    "        plt.suptitle(f'Boxplot and histplot for \"{str(column).upper()}\"', fontsize=17)\n",
    "        \n",
    "        fig_ax_1 = fig.add_subplot(grd[1,0])\n",
    "        plt.grid(True)\n",
    "        sns.set_style('darkgrid')\n",
    "        hist = sns.histplot(data=data_df, x=column,\n",
    "                            multiple='stack',\n",
    "                            alpha=0.25, legend=False, kde=True,\n",
    "                            linewidth=3)\n",
    "        for line in hist.lines:\n",
    "            line.set_linewidth(5)\n",
    "        median_line_full_data_df = plt.axvline(np.median(data_df[column]), \n",
    "                                             color='indigo', \n",
    "                                             linestyle='-',\n",
    "                                             lw=2,   \n",
    "                                             label=f'Median line of feature')\n",
    "        left_border_line_full_data_df= plt.axvline(left_border_full, \n",
    "                                                  color='m', \n",
    "                                                  linestyle=':',\n",
    "                                                  lw=3,\n",
    "                                                  label=f'First quantile of {str(column).upper()} for full feature')\n",
    "        right_border_line_full_data_df = plt.axvline(right_border_full, \n",
    "                                                   color='m', \n",
    "                                                   linestyle='-.',\n",
    "                                                   lw=3,\n",
    "                                                   label=f'Third quantile of {str(column).upper()} for full feature') \n",
    "        plt.xlabel('Values', fontsize=15)\n",
    "        plt.ylabel('Counts', fontsize=15)\n",
    "\n",
    "        \n",
    "        fig_ax_2 = fig.add_subplot(grd[0,0])\n",
    "        sns.set_style('darkgrid')\n",
    "        plt.grid(True)\n",
    "        ax = sns.boxplot(x=column, data=data_df, palette=['blue'],\n",
    "                         orient=\"h\", showcaps=False, notch=True, medianprops={\"color\": \"indigo\"}, boxprops=dict(alpha=.5))\n",
    "        mean_line_full_data_df = plt.axvline(np.mean(data_df[column]), \n",
    "                                           color='black', \n",
    "                                           linestyle='--',\n",
    "                                           lw=3,\n",
    "                                           label=f'Mean line of feature')\n",
    "        median_line_full_data_df= plt.axvline(np.median(data_df[column]), \n",
    "                                             color='indigo', \n",
    "                                             linestyle='-',\n",
    "                                             lw=3,   \n",
    "                                             label=f'Median line of feature')\n",
    "        left_border_line_full_data_df = plt.axvline(left_border_full, \n",
    "                                                  color='m', \n",
    "                                                  linestyle=':',\n",
    "                                                  lw=3,\n",
    "                                                  label=f'First quantile of {str(column).upper()} for full feature')\n",
    "        right_border_line_full_data_df = plt.axvline(right_border_full, \n",
    "                                                   color='m', \n",
    "                                                   linestyle='-.',\n",
    "                                                   lw=3,\n",
    "                                                   label=f'Third quantile of {str(column).upper()} for full feature') \n",
    "        plt.ylabel(f'{column}', fontsize=15)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        \n",
    "        plt.legend(title=f'Legend for \"{str(column).upper()}\"',\n",
    "                   handles=[Patch(color='blue', alpha=.5, label='Full feature'),\n",
    "                            Patch(color='red', alpha=.5, label='Disaster'),\n",
    "                            Patch(color='green', alpha=.5, label='Not disaster'),\n",
    "                            mean_line_full_data_df,\n",
    "                            median_line_full_data_df,\n",
    "                            left_border_line_full_data_df,\n",
    "                            right_border_line_full_data_df,\n",
    "                            Line2D([0], [0], color='green', lw=2, label='Distibution for disaster for not disaster'),\n",
    "                            Line2D([0], [0], color='red', lw=2, label='Distibution for disaster'),\n",
    "                            Patch(color='none', label=f'Num outliers full-{outliers_full:.2f}'),\n",
    "                            Patch(color='none', label=f'Std value-{data_df[column].std():.2f}'),\n",
    "                            Patch(color='none', label=f'Mean value-{np.mean(data_df[column]):.2f}'),\n",
    "                            Patch(color='none', label=f'Median value-{np.median(data_df[column]):.2f}'),],\n",
    "                   \n",
    "                   edgecolor = 'r',\n",
    "                   facecolor = 'oldlace',\n",
    "                   ncol=3,\n",
    "                   title_fontsize=17,\n",
    "                   fontsize=15,\n",
    "                   loc='center',\n",
    "                   bbox_to_anchor=(0.5, -1.45));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(feature: str) -> None:\n",
    "    plt.figure(figsize=[15, 7])\n",
    "    plt.subplots_adjust(top=0.88, wspace=0.3, hspace=0.95)\n",
    "    plt.suptitle('Distibution and Probalities', fontsize=15)\n",
    "    sns.set_style('darkgrid')\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Distibution for train', fontsize=13)\n",
    "    mu, std = np.mean(data_df[feature]), np.std(data_df[feature])\n",
    "    x = np.linspace(mu - 3*std, mu + 3*std, 100)\n",
    "    pdf = norm.pdf(x, mu, std)\n",
    "    sns.kdeplot(data_df[feature], label=f'Distibution of {feature}', legend=True, )\n",
    "    sns.lineplot(x=x, y=pdf, color='red', label=f'Normal distribution of {feature}')\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.legend(edgecolor = 'r',\n",
    "               facecolor = 'oldlace',\n",
    "               ncol=1,\n",
    "               fontsize=15,\n",
    "               loc='center',\n",
    "               bbox_to_anchor=(0.5, -0.5))\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('Distribution for test', fontsize=13)\n",
    "    mu, std = np.mean(closed_data[feature]), np.std(closed_data[feature])\n",
    "    x = np.linspace(mu - 3*std, mu + 3*std, 100)\n",
    "    pdf = norm.pdf(x, mu, std)\n",
    "    sns.kdeplot(closed_data[feature], label=f'Distribution of {feature}', legend=True)\n",
    "    sns.lineplot(x=x, y=pdf, color='red', label=f'Normal distribution of {feature}')\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.legend(edgecolor = 'r',\n",
    "               facecolor = 'oldlace',\n",
    "               ncol=1,\n",
    "               fontsize=15,\n",
    "               loc='center',\n",
    "               bbox_to_anchor=(0.5, -0.5))\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    stats.probplot(data_df[feature], plot=plt)\n",
    "    plt.title('Probalitiplot for train', fontsize=13)\n",
    "    plt.ylabel('Ordered values', fontsize=12)\n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    stats.probplot(closed_data[feature], plot=plt)\n",
    "    plt.title('Probalitiplot for test', fontsize=13)\n",
    "    plt.ylabel('Ordered values', fontsize=12)\n",
    "    plt.xlabel(feature, fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,12))\n",
    "plt.title('CORRELATION MATRIX (PEARSON).', fontsize=20)\n",
    "sns.heatmap(data_df.corr(numeric_only=True), annot=True, cmap=\"coolwarm\",  fmt='.2g', linewidth=4)\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_point_biserial = []\n",
    "for column in data_df.columns:\n",
    "    correlations_point_biserial.append(stats.pointbiserialr(data_df[column], target)[0])\n",
    "df_with_point_biserial_corr = pd.DataFrame({'column': data_df.columns.tolist(),\n",
    "                                            'correlation point biserial': correlations_point_biserial}) \\\n",
    "                                            .set_index('column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,12))\n",
    "plt.title('POINT-BISERIAL CORRELATION.', fontsize=20)\n",
    "sns.heatmap(df_with_point_biserial_corr,\n",
    "            annot=True,\n",
    "            cmap=\"coolwarm\",\n",
    "            fmt='.2g',\n",
    "            linewidth=4)\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Values')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data_df, x='0', y='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(data_df, alpha=0.2, figsize=(6, 6), diagonal=\"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_for_model = ['0', '1', '2' ,'3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[f_for_model]\n",
    "closed_data = closed_data[f_for_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(data_df, alpha=0.2, figsize=(6, 6), diagonal=\"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_df[data_df['2'] < data_df['2'].quantile(q=0.25)]['2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[data_df['2'] >= data_df['2'].quantile(q=0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "data_df = scaler.fit_transform(data_df.drop(['target'], axis=1))\n",
    "closed_data = scaler.transform(closed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(Ridge(), scoring='neg_mean_squared_error', cv=15, \n",
    "                    param_grid={'alpha': np.linspace(0,1, num=100),\n",
    "                                'max_iter': [1000, 1500, 2000, 2500, 3000],\n",
    "                                'random_state':[42]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(data_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(random_state=42, alpha=0.18181818181818182, max_iter=1000)\n",
    "ridge.fit(data_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, eval_data, step=10):\n",
    "    predicted_values = model.predict(eval_data)\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем ваше внимание, предсказания округляются до сотых!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = np.round(get_predictions(model=ridge, eval_data=closed_data), 2)\n",
    "\n",
    "assert predicted_values.shape == (closed_data.shape[0], ) # predictions should be just one-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def float_list_to_comma_separated_str(_list):\n",
    "    _list = list(np.round(np.array(_list), 2))\n",
    "    return ','.join([str(x) for x in _list])\n",
    "\n",
    "submission_dict = {\n",
    "    'predictions': float_list_to_comma_separated_str(predicted_values)\n",
    "}\n",
    "with open('submission_dict_final_p01.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "    \n",
    "print('File saved to `submission_dict_final_p01.npy`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель №2\n",
    "Функция `my_transformation` принимает на вход матрицу объект-признак (`numpy.ndarray` типа `np.float`) и преобразует ее в новую матрицу. Данная функция может использовать только numpy-операции, а также арифметические действия.\n",
    "\n",
    "Для примера доступна функция ниже. Она лишь добавляет новый признак, представляющий собой произведение первого и второго исходных признаков (считая с нуля)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_transformation(feature_matrix: np.ndarray):\n",
    "    new = feature_matrix[:, :4]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-30 22:08:50--  https://raw.githubusercontent.com/girafe-ai/ml-course/23f_yandex_ml_trainings/homeworks/assignment_final/hw_final_open_data.npy\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 44928 (44K) [application/octet-stream]\n",
      "Сохранение в: «hw_final_open_data.npy»\n",
      "\n",
      "hw_final_open_data. 100%[===================>]  43,88K  --.-KB/s    за 0,04s   \n",
      "\n",
      "2023-11-30 22:08:51 (1,16 MB/s) - «hw_final_open_data.npy» сохранён [44928/44928]\n",
      "\n",
      "--2023-11-30 22:08:51--  https://raw.githubusercontent.com/girafe-ai/ml-course/23f_yandex_ml_trainings/homeworks/assignment_final/hw_final_open_target.npy\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 6528 (6,4K) [application/octet-stream]\n",
      "Сохранение в: «hw_final_open_target.npy»\n",
      "\n",
      "hw_final_open_targe 100%[===================>]   6,38K  --.-KB/s    за 0s      \n",
      "\n",
      "2023-11-30 22:08:51 (34,6 MB/s) - «hw_final_open_target.npy» сохранён [6528/6528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/23f_yandex_ml_trainings/homeworks/assignment_final/hw_final_open_data.npy -O hw_final_open_data.npy\n",
    "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/23f_yandex_ml_trainings/homeworks/assignment_final/hw_final_open_target.npy -O hw_final_open_target.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('hw_final_open_data.npy', allow_pickle=False)\n",
    "target = np.load('hw_final_open_target.npy', allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_x = my_transformation(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse =\t 0.08574\n",
      "validation mse = 0.09955\n"
     ]
    }
   ],
   "source": [
    "lr = Ridge(random_state=42, alpha=0.18181818181818182, max_iter=1000)\n",
    "lr.fit(transformed_train_x, train_y)\n",
    "\n",
    "print(\n",
    "    f'train mse =\\t {mean_squared_error(lr.predict(transformed_train_x), train_y):.5f}',\n",
    "    f'validation mse = {mean_squared_error(lr.predict(my_transformation(valid_x)), valid_y):.5f}',\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем ваше внимание, что параметры линейной модели будут округляться до __четырех знаков после запятой__. Это не должно сильно повлиять на качество предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_predictions = lr.predict(transformed_train_x)\n",
    "rounded_predictions = transformed_train_x.dot(np.round(lr.coef_, 4)) + np.round(lr.intercept_, 4)\n",
    "\n",
    "\n",
    "assert np.allclose(original_predictions, rounded_predictions, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры вашей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_submission = [0.0418, 2.9833, 0.0, 2.4812]\n",
      "b_submission = 2.965\n"
     ]
    }
   ],
   "source": [
    "w_list = list(np.round(lr.coef_, 4))\n",
    "print(f'w_submission = {list(np.round(lr.coef_, 4))}\\nb_submission = {np.round(lr.intercept_, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминаем, ваша модель не должна использовать более 15 параметров (14 весов плюс свободный член)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(w_list) + 1 <= 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сдача второй части соревнования\n",
    "Для сдачи вам достаточно отправить функцию `my_transformation` и параметры вашей модели в контест в задачу №2. Пример посылки доступен ниже. Имортирование `numpy` также необходимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________example_submission_start__________\n",
    "import numpy as np\n",
    "def my_transformation(feature_matrix: np.ndarray):\n",
    "    new_feature_matrix = np.zeros((feature_matrix.shape[0], feature_matrix.shape[1]+1))\n",
    "    new_feature_matrix[:, :feature_matrix.shape[1]] = feature_matrix\n",
    "    new_feature_matrix[:, -1] = feature_matrix[:, 0\n",
    "    ] * feature_matrix[:, 1]\n",
    "    return new_feature_matrix\n",
    "\n",
    "w_submission = [-0.0027, -0.2637, 0.0, -0.1134, -0.0165, -0.9329, 0.0, 0.1293]\n",
    "b_submission = 1.1312\n",
    "# __________example_submission_end__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
